연습 (5.6) 실습 코드의 ① 네트워크 구조를 아래와 같이 변경해 보고 ② 은닉층의 활성화 함수를 ‘relu’,‘sigmoid’, ‘tanh’ 별로 입력하여 그 결과를 비교해 보자. 
어떤 활성화 함수가 가장 효율적으로 학습이 되었는지 비교해보자 
(최종 출력 레이어는 동일하게 softmax). 
③ 최적화 방법을 Adam, SGD, 경사하강법 순서대로 비교해 보고 어느 최적화 방법이 가장 좋은 성능을 보여주는지 알아보자.
④ 가장 좋은 성능을 내는 최적화 방법과 활성화 함수를 선택하고 학습과정을 epoch회수에 따른 loss와 accuracy그래프로 표현해 보자.
 
① 네트워크 구조를 변경 코드 기술
② 은닉층의 활성화 함수를 ‘relu’,‘sigmoid’, ‘tanh’ 별로 다르게 입력하여 그 결과를 비교
③ 최적화 방법을 Adam, SGD, 경사하강법 순서대로 비교해 보고 어느 최적화 방법이 가장 좋은 성능을 보여주는지 설명
④ 가장 좋은 성능을 내는 최적화 방법과 활성화 함수를 선택하고 학습 과정을 epoch회수에 따른 loss와 accuracy 그래프로 표현해 보자
